{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfnRHFBEhLTiGEvzoSINQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaManari/MLPNS_EManari/blob/main/Appunti_2_maggio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQehWbWD6InH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_TTX9u3X6PTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning\n",
        "Layer connectivity: sparcely cnnected. \n",
        "Quandfo costruisco l'architettura del NN la dimensione del layer precedente determina la dimensione del layer dopo. Tutte le operazioni sono invertibili : backpropagation per imparare i pesi corretti. Il proposito del NN è approssimare la funzione phi.. dati input - output non lineare, ma NN è lineare.. come faccio ? La complessita del NN ci consente di passare da non linear a linear . \n",
        "passare dal lineare al non lineare . Tutti gli elementi sono quadrati, mettendoli insieme ottengo la non linearità. \n",
        "Guardare capitolo 4 del libro online Deep Learning and NN . Relazione non lineare fra input e output , il neurone è lineare, più neuroni metto più approssimo meglio la non linearità. \n",
        "Regole di base per scegliere elementi architettonici del NN, attenzione all'overfitting. Più è profondo più risorse ci vogliono per trainarlo. \n",
        "Alcune scelte che si possono fare: loss function appropriata al task che voglio realizzare. Ma si può anche non rispettare. Problema di classificazione a volte migliora il NN. Si possno violare le regole. \n",
        "# Loss function\n",
        "La loss function è molto noisy aggiusto il learning rate, quantità di offset che m,etto nei pesi sulla base di quanto sono lontana dai risultati è troppo grande. Se ho discontinuità nella loss function, cambio funzione di attivazione. Chiedo al NN si salvare l'epoca migliore del NN . scelgo i pesi prima dello sbalzo. La validation loss non deve appiattirsi mentre il training loss va avanti. Training loss vs validation loss. Guida architettura NN. \n",
        "\n",
        "# Generative AI \n",
        "Applicazioni comuni: style transforming and subject transorming. L'aspetto generativo : non produco un risultato che so. Rirpoduco dati che nn esistono ma consistenti con le caratteristiche che imparo con il NN. (translation)\n",
        "Applicazioni: creo immagini che non esistono. (semantic image). \n",
        "1) I nostri NN hanno bisogno di molti dati. Aumento i dati. \n",
        "2) Semantic image\n",
        "3) image resolution increase\n",
        "4) Text to speech  generator\n",
        "5) convertitore di linguaggi \n",
        "6) Fai una domanda e GAI risponde alla domanda. Molto utilizzo di AI production. Il processo creativo passa da un modello Ai per iniziare il processo creativo o raffinarlo. Testo per farlo scriverte meglio. \n",
        "7) Music generation: si possono produrre pezzi di musica.. \n",
        "8) Image to image conversion\n",
        "9) text to image conversion: Dall-e --> prodotti di google \n",
        "10) aumentare dimensione dataset \n",
        "11) image to text : commenta le immagini , per i non vedenti. Descrizioni delle foto. \n",
        "\n",
        "# Architetture basi di G AI \n",
        "1) transformer architecture, time series analysis, language\n",
        "2) GAN \n",
        "3) Variation auto encoder : VAE \n",
        "4) Diffusion models\n",
        "5) flow based models\n",
        "GAN's\n",
        "\n",
        "# Autoencoder's\n",
        "Sono i più semplici: tutti gli elementi architettonici già visti ma messi insieme in modo diverso. Ritenere le info dei dati originali e di perdere il noise, ciò che non è inerente alla styruttura dei dati. Se i hidden layer più piccole dei dati: compressione dei dati in input. Se i CNL diminuiscono --> compressione non lineare dei dati in input. Dimensionality reduction. \n",
        "Representation of the data. Parto da 5 features e poi arrivo a due in output. Encoder model dell'auto encoder. Autoencoder = encoder + decoder . Impara una rappresentazione compressa che è in grado di darmi i dati in input. Applicazione originaria: ricrea i dati che gli ho dati passanfdo per un layer più piccolo detto bottle net. Input : lower --> output: higher resolution. Devo dare dimensione maggiore. \n",
        "NN non convolutional . Dense layer lo trasformo in un convolutional .. maxfully : riduco dimensione del layer, upsample : ingrandisce le dimensioni del layer, operazione inversa del maxfully. \n",
        "NN sequential, linear. \n",
        "Autoencoder : quando diminuisco il numero dei neuroni e poi li riaumento. Si passano multipli di 12 neuroni, più facile computazionalmente. \n",
        "Encoder - bottle neck - decoder. Serve per esempio dare immagini a più alta risoluzione. \n",
        "Se voglio creare molti dati, voglio avere dataset più grande: traino lì'encoder ma poi uso il decoder con pochi dati in input. \n",
        "Compressione: uso solo l'encoder part : serve per salvare dati in maniera compatta. Bottle neck: salvo solo esso. \n",
        "\n",
        "# NN per ricostruire cifre scritte a mano. Da apploadare da keras. \n",
        "Problema di predizione: regression . Per ogni pixel devo trovare un value che è un pixel. Layer più piccolo . predizione per come era l'immagine in precedenza. Regressione: mean square error --> predizxione. I risultati ottenuti hanno troppa struttura, troppi grigi rispetto all'originale. siccome c'è gradiente così alto fra nero bianco : cambio l'attivazione dell'ultimo layer con sigmoid, poi la loss function e mett la loss function relativa all'activation function. \n",
        "Sequential linear non convolutional..\n",
        "Ci vuole molto tempo per il training. \n",
        "Convolutional NN : preserva la forma dell'immagine.\n",
        "Se voglio solo avere il contenuto delk solo pixel, sequential e non convolutional, srotolo le immagini in un singolo array di pixel. \n",
        "Posterior collapse = impara la predizione media. Regression to de mean . Impara il risultato medio, non quiello che voglio ottenere. \n",
        "Latent space: 16 neuroni , linea con 16 pixel\n",
        "Ciascun dato in input ha il latent space e rappr in output. Come il latent space è mappato nell'output. \n",
        "\n",
        "# Variational autoencoder\n",
        "Goal: aumento la risoluzione dell'immagine. \n",
        "Riduco l'immagine di input per poi dargli la risoluzione di questa imagine come output\n",
        "Al posto di dense layer devo metterci i convolutional layer\n",
        "Perchè alcune predizioni sono migliori di altri. \n",
        "Stesso enviroment camera. \n",
        "La predizione su studenti femmine e cc ecc è peggiore di quelli trainati (maschio bianco), deviazioni, predizione fatta male. Oppure l'immagine non è centrata. Il data set era caratteistico della popolazione americana. Caratteristico della popolazione americana bianca. la predizione deve essere bianca. problema tecnico e sociale. Etica delle AI significative. \n",
        "Problema originario: diversità dati, e come il modello è convalidato. Se il test set fosse stato bilanciato, allora non ci sarebbe stato il problema. Falliva su classi speifiche di dati. \n",
        "\n",
        "#Ethic's of AI\n",
        "\n",
        "Ritratti della popolazione globale, retraina il modello per ottenere risultati migliori. \n",
        "\n",
        "# Compito \n",
        "\n",
        "Il convolutional autoencoders funziona megli, anche relazione con altri pixel. \n",
        "\n",
        "# Diversi modelli di G AI \n",
        "variational autoencoders: problema. Se passo dal predirre la mia immagine, quanfdo arrivo al latent space per strarre variabili devo assumere una distribuzione sul latent space, ad esempio una gaussiana. Supongono gaussianità nel latent space. Così le immagini prodotte dal decoder sono meno dettagliate delle originalki. Flow based models: si adatta a diverse architetture --> Normalizing flow: NN molto semplice , neuroni individuali in serie, no multineural, vedono quel è la distribuzione del latent space : latent space - normalizing flow - decoder\n",
        "\n",
        "# Gans \n",
        "2014, strutture di due neural networks, decoder ed encoder. Essi funzionano in parallelo non in serie . Prime immagini fatte a caso, il discriminatore impara a capuire se è immagine vera o artificiale, il generatore impara a  fare immagini realistiche. Adversaria, sono in competizione matematica, uno massimizza (discriminatore) la loss , min la loss (generatore , diff tra immagini finte e vere)\n",
        "MinMax loss function. \n",
        "\n"
      ],
      "metadata": {
        "id": "piqG_8tQ6WW7"
      }
    }
  ]
}