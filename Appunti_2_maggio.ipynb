{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIg1GuOCeDYuE9SLVDDNfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenaManari/MLPNS_EManari/blob/main/Appunti_2_maggio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQehWbWD6InH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_TTX9u3X6PTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning\n",
        "Layer connectivity: sparcely cnnected. \n",
        "Quandfo costruisco l'architettura del NN la dimensione del layer precedente determina la dimensione del layer dopo. Tutte le operazioni sono invertibili : backpropagation per imparare i pesi corretti. Il proposito del NN è approssimare la funzione phi.. dati input - output non lineare, ma NN è lineare.. come faccio ? La complessita del NN ci consente di passare da non linear a linear . \n",
        "passare dal lineare al non lineare . Tutti gli elementi sono quadrati, mettendoli insieme ottengo la non linearità. \n",
        "Guardare capitolo 4 del libro online Deep Learning and NN . Relazione non lineare fra input e output , il neurone è lineare, più neuroni metto più approssimo meglio la non linearità. \n",
        "Regole di base per scegliere elementi architettonici del NN, attenzione all'overfitting. Più è profondo più risorse ci vogliono per trainarlo. \n",
        "Alcune scelte che si possono fare: loss function appropriata al task che voglio realizzare. Ma si può anche non rispettare. Problema di classificazione a volte migliora il NN. Si possno violare le regole. \n",
        "# Loss function\n",
        "La loss function è molto noisy aggiusto il learning rate, quantità di offset che m,etto nei pesi sulla base di quanto sono lontana dai risultati è troppo grande. Se ho discontinuità nella loss function, cambio funzione di attivazione. Chiedo al NN si salvare l'epoca migliore del NN . scelgo i pesi prima dello sbalzo. La validation loss non deve appiattirsi mentre il training loss va avanti. Training loss vs validation loss. Guida architettura NN. \n",
        "\n",
        "# Generative AI \n",
        "Applicazioni comuni: style transforming and subject transorming. L'aspetto generativo : non produco un risultato che so. Rirpoduco dati che nn esistono ma consistenti con le caratteristiche che imparo con il NN. (translation)\n",
        "Applicazioni: creo immagini che non esistono. (semantic image). \n",
        "1) I nostri NN hanno bisogno di molti dati. Aumento i dati. \n",
        "2) Semantic image\n",
        "3) image resolution increase\n",
        "4) Text to speech  generator\n",
        "5) convertitore di linguaggi \n",
        "6) Fai una domanda e GAI risponde alla domanda. Molto utilizzo di AI production. Il processo creativo passa da un modello Ai per iniziare il processo creativo o raffinarlo. Testo per farlo scriverte meglio. \n",
        "7) Music generation: si possono produrre pezzi di musica.. \n",
        "8) Image to image conversion\n",
        "9) text to image conversion: Dall-e --> prodotti di google \n",
        "10) aumentare dimensione dataset \n",
        "11) image to text : commenta le immagini , per i non vedenti. Descrizioni delle foto. \n",
        "\n",
        "# Architetture basi di G AI \n",
        "1) transformer architecture, time series analysis, language\n",
        "2) GAN \n",
        "3) Variation auto encoder : VAE \n",
        "4) Diffusion models\n",
        "5) flow based models\n",
        "GAN's\n",
        "\n",
        "# Autoencoder's\n",
        "Sono i più semplici: tutti gli elementi architettonici già visti ma messi insieme in modo diverso. Ritenere le info dei dati originali e di perdere il noise, ciò che non è inerente alla styruttura dei dati. Se i hidden layer più piccole dei dati: compressione dei dati in input. Se i CNL diminuiscono --> compressione non lineare dei dati in input. Dimensionality reduction. \n",
        "Representation of the data. Parto da 5 features e poi arrivo a due in output. Encoder model dell'auto encoder. Autoencoder = encoder + decoder . Impara una rappresentazione compressa che è in grado di darmi i dati in input. Applicazione originaria: ricrea i dati che gli ho dati passanfdo per un layer più piccolo detto bottle net. Input : lower --> output: higher resolution. Devo dare dimensione maggiore. \n",
        "NN non convolutional . Dense layer lo trasformo in un convolutional .. maxfully : riduco dimensione del layer, upsample : ingrandisce le dimensioni del layer, operazione inversa del maxfully. \n",
        "NN sequential, linear. \n",
        "Autoencoder : quando diminuisco il numero dei neuroni e poi li riaumento. Si passano multipli di 12 neuroni, più facile computazionalmente. \n",
        "Encoder - bottle neck - decoder. Serve per esempio dare immagini a più alta risoluzione. \n",
        "Se voglio creare molti dati, voglio avere dataset più grande: traino lì'encoder ma poi uso il decoder con pochi dati in input. \n",
        "Compressione: uso solo l'encoder part : serve per salvare dati in maniera compatta. Bottle neck: salvo solo esso. \n",
        "\n",
        "# NN per ricostruire cifre scritte a mano. Da apploadare da keras. \n",
        "Problema di predizione: regression . Per ogni pixel devo trovare un value che è un pixel. Layer più piccolo . predizione per come era l'immagine in precedenza. Regressione: mean square error --> predizxione. I risultati ottenuti hanno troppa struttura, troppi grigi rispetto all'originale. siccome c'è gradiente così alto fra nero bianco : cambio l'attivazione dell'ultimo layer con sigmoid, poi la loss function e mett la loss function relativa all'activation function. \n",
        "Sequential linear non convolutional..\n",
        "Ci vuole molto tempo per il training. \n"
      ],
      "metadata": {
        "id": "piqG_8tQ6WW7"
      }
    }
  ]
}